{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4jj-XbwQsi2C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "be2ad42d2424421c8be5eab1b460743f",
            "10e58323e2484ce080e6f424378e1a42",
            "2f162149bc8643dc8c9d52b474d58833",
            "4c026cb59d624f188fb0aa4ed3be36cf",
            "714556ff099846f8ac2e9488910118f4",
            "b280c346ee804e018b5fa9e1ac3b5c92",
            "6bc02745a07543fba79faba379a85833",
            "22528494403d44bb84789492adb775f5",
            "9fb2d991799940fcab5649eaf4224279",
            "e7f59733c6cc45f383d4d71b6befc98c",
            "e7ad2fdc68cb4996bcb3b6dda498a420"
          ]
        },
        "id": "o30-Lh_vstPC",
        "outputId": "6ea0a400-1952-402d-94f1-a84ed740e46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root = './data',train = True, download = True,transform = transform)\n",
        "testset = torchvision.datasets.CIFAR10(root = './data',train = False, download = True,transform = transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 64, shuffle=True, num_workers = 2)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size = 64, shuffle=True, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qAHmE3WtRSX",
        "outputId": "f14f750f-21c2-4f5a-8ff2-3c4eb1bb6a9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# do I have cuda\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WxLJOZm5uZN7"
      },
      "outputs": [],
      "source": [
        "# after making sure cuda is available, we need to create a cuda device object that represent particular nvidia GPU \n",
        "# if GPU is not available we put an else to avoid error , using cpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "35oC65r0szGL"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "       nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3,stride=1,padding=1),  # (i-f+2p)/s  + 1  (32-3+2)/1  +1\n",
        "       nn.MaxPool2d(kernel_size=2,stride=2), # (M-P)/s + 1  (32-2)/2 + 1 = 16\n",
        "       nn.ReLU(),\n",
        "       nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,stride=1,padding=1), \n",
        "       nn.MaxPool2d(kernel_size=2,stride=2),   # (M-P)/s + 1  (16-2)/2 +1  = 8\n",
        "       nn.ReLU()\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "       nn.Linear(in_features=32*8*8,out_features=64),\n",
        "       nn.ReLU(),\n",
        "       nn.Linear(in_features=64,out_features=10)  \n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(x.size(0),-1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# the only line is different from previous version with out CUDA is here, it was 'model = CNN()', but now :\n",
        "model = CNN().to(device)\n",
        "# we refere the convolutional network instance called model, to device object to use cuda instead of cpu "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "va67m8mNvXE4"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDpvYiSCvdtq",
        "outputId": "6325a1f0-f899-4e5c-aec2-277e74e8d17c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30] Training Accuracy: 0.3002 Loss: 2.1030\n",
            "Epoch [2/30] Training Accuracy: 0.3673 Loss: 1.7227\n",
            "Epoch [3/30] Training Accuracy: 0.4755 Loss: 1.5241\n",
            "Epoch [4/30] Training Accuracy: 0.4723 Loss: 1.4137\n",
            "Epoch [5/30] Training Accuracy: 0.5396 Loss: 1.3344\n",
            "Epoch [6/30] Training Accuracy: 0.5258 Loss: 1.2677\n",
            "Epoch [7/30] Training Accuracy: 0.5717 Loss: 1.2102\n",
            "Epoch [8/30] Training Accuracy: 0.6022 Loss: 1.1596\n",
            "Epoch [9/30] Training Accuracy: 0.5729 Loss: 1.1136\n",
            "Epoch [10/30] Training Accuracy: 0.6142 Loss: 1.0757\n",
            "Training took 207.45 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "loss_list = []\n",
        "accuracy_list = []\n",
        "for epoch in range(10):\n",
        "    epoch_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # image and labels also should be refered to device object using cuda\n",
        "        # so we add these two lines\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    loss_list.append(epoch_loss / len(trainloader))\n",
        "\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in trainloader:\n",
        "            # image and labels also should be refered to device object using cuda\n",
        "            # so we add these two lines\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            accuracy = correct / total\n",
        "            accuracy_list.append(accuracy)\n",
        "\n",
        "        print(\"Epoch [{}/30] Training Accuracy: {:.4f}\".format(epoch + 1, correct / total),\"Loss: {:.4f}\".format(loss_list[-1]))\n",
        "\n",
        "print(\"Training took {:.2f} seconds\".format(time.time() - start_time))\n",
        "\n",
        "\n",
        "# the training time process using GPU took less time, GPU is way faster\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v38hHHwshx8S",
        "outputId": "71ffce42-f4f4-4b8a-dac1-c01327ee65fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5970\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0 \n",
        "  total = 0\n",
        "  for images, labels in testloader:\n",
        "    # image and labels also should be refered to device object using cuda\n",
        "    # so we add these two lines\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print('Test Accuracy: {:.4f}'.format(correct/total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yyEUZi5KvFzK"
      },
      "outputs": [],
      "source": [
        "# create a dictionary to save th etrained model\n",
        "save_state = {'model':model.state_dict(), 'optimizer':optimizer.state_dict()}\n",
        "torch.save(save_state, r'C:\\Users\\TE580354\\OneDrive - TE Connectivity\\51-1880822\\focus_checker\\code\\CNN_GPU.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hJXpgnxpxZ3k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TE580354\\AppData\\Local\\Temp\\ipykernel_12596\\4289054098.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(r'C:\\Users\\TE580354\\OneDrive - TE Connectivity\\51-1880822\\focus_checker\\code\\CNN_GPU.pth')\n"
          ]
        }
      ],
      "source": [
        "# test the saved model if works, lets load the model and its optimizer\n",
        "# u can use this part in a seperate notebook, withouttraining before, as the model is saved and we need just to load it\n",
        "state = torch.load(r'C:\\Users\\TE580354\\OneDrive - TE Connectivity\\51-1880822\\focus_checker\\code\\CNN_GPU.pth')\n",
        "model.load_state_dict(state['model'])\n",
        "optimizer.load_state_dict(state['optimizer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZpwVufrygPy",
        "outputId": "5771552d-4a44-43eb-a7da-55baa6d7a35d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5970\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "  correct = 0 \n",
        "  total = 0\n",
        "  for images, labels in testloader:\n",
        "    # to use GPU we add .to(device)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    outputs = model(images)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print('Test Accuracy: {:.4f}'.format(correct/total))\n",
        "  # so it worked"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10e58323e2484ce080e6f424378e1a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b280c346ee804e018b5fa9e1ac3b5c92",
            "placeholder": "​",
            "style": "IPY_MODEL_6bc02745a07543fba79faba379a85833",
            "value": "100%"
          }
        },
        "22528494403d44bb84789492adb775f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f162149bc8643dc8c9d52b474d58833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22528494403d44bb84789492adb775f5",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fb2d991799940fcab5649eaf4224279",
            "value": 170498071
          }
        },
        "4c026cb59d624f188fb0aa4ed3be36cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f59733c6cc45f383d4d71b6befc98c",
            "placeholder": "​",
            "style": "IPY_MODEL_e7ad2fdc68cb4996bcb3b6dda498a420",
            "value": " 170498071/170498071 [00:03&lt;00:00, 42282111.56it/s]"
          }
        },
        "6bc02745a07543fba79faba379a85833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "714556ff099846f8ac2e9488910118f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb2d991799940fcab5649eaf4224279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b280c346ee804e018b5fa9e1ac3b5c92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2ad42d2424421c8be5eab1b460743f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10e58323e2484ce080e6f424378e1a42",
              "IPY_MODEL_2f162149bc8643dc8c9d52b474d58833",
              "IPY_MODEL_4c026cb59d624f188fb0aa4ed3be36cf"
            ],
            "layout": "IPY_MODEL_714556ff099846f8ac2e9488910118f4"
          }
        },
        "e7ad2fdc68cb4996bcb3b6dda498a420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7f59733c6cc45f383d4d71b6befc98c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
